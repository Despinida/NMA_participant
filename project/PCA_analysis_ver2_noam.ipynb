{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"PCA_analysis_ver2_noam.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"1rpsmNP0Bw76","colab_type":"code","cellView":"both","colab":{}},"source":["#@title Libraries\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import scipy\n","from scipy import sparse\n","import os.path\n","from os import path\n","import pickle\n","from scipy import stats\n","from sklearn.decomposition import FastICA"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XOemCG20CpVu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596033917725,"user_tz":-120,"elapsed":1070,"user":{"displayName":"Danica DespotoviÄ‡","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXOEz7yOl22-N2YvI8U0Ncih7xuPEu6bx-QmjQOA=s64","userId":"16625330314888409421"}},"outputId":"a7004aad-026b-4d48-ce5b-4c6f0ed24ea9"},"source":["# if your data is not in Colab, click on 'mount Drive' under Files on the left\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fugWMhiZDdAi","colab_type":"code","colab":{}},"source":["def load_all_timestamps_of_trials(drivepath):\n","  '''\n","  Simply loads all the time_stamped arrays from all trials in the order they occur relative to each other.\n","  each array is of size [nTrials,]\n","\n","  Input: drivepath (file location)\n","  Output: trial_times, vis_stim, goCue, resp_times, feedback_times\n","  '''\n","  trial_times = np.load(drivepath+'trials.intervals.npy') # in seconds. stim starts after wheel was still for 1.5 s\n","  vis_stim = np.load(drivepath+'trials.visualStim_times.npy')\n","  goCue = np.load(drivepath+'trials.goCue_times.npy') # in seconds, this is after seeing the stimulus. now the mouse can move the wheel which is now coupled ot the stim location\n","  resp_times = np.load(drivepath+'trials.response_times.npy')\n","  feedback_times = np.load(drivepath+'trials.feedback_times.npy') # is shortly before end of interval (trial_times[:,1])\n","  \n","  # During the 1 s feedback period, the visual stimulus remained on the screen. After a subsequent inter-trial interval of 1 s, [...from paper]\n","  return trial_times, vis_stim, goCue, resp_times, feedback_times\n","\n","# PCA analysis\n","def smoothHist(hist, binsize, SD):\n","  '''\n","  to smooth single spike trains\n","  input:  hist: spike train, size: [nNeurons\n","  '''\n","  edges = np.arange(-3.0*SD, 3.0*SD, binsize)\n","  kernel = (1.0/(6.0*(SD**2)))*((np.sqrt(6.0)*SD)-np.abs(edges)) # a triangular kernel\n","  m = np.min(kernel) \n","  kernel = kernel + np.abs(m)\n","  kernel = kernel/np.sum(kernel)\n","  half_length = int((len(kernel)-1)/2)\n","  \n","  smHist = []\n","  \n","  for celli in range(np.shape(hist)[0]):\n","    row = hist[celli,:]\n","    temp = np.convolve(row, kernel)   \n","    smHist.append(temp[half_length:-1-half_length])\n","  \n","  return np.array(smHist)\n","\n","def concatenate_trials(input_dict, pick): \n"," # functions to concatenate trials if the input is dictionary\n"," # expected input is of shape like output of getHistTrials\n"," \n","  keys = np.array(list(spikes.keys()))\n","  no_trials, _ = np.shape(keys) \n","  no_neurons = np.shape(input_dict[0,pick])[0]\n","  out = input_dict[0,pick] # first trial\n","  for trials in np.arange(1, int(no_trials/4)):\n","    out = np.concatenate([out, input_dict[trials,pick]], axis = 1) # concatenating \n","\n","  return out\n","\n","def concatenate_trials_by_feedbackoutput(spikes_hist, pick, feedback, correct=True): \n"," # functions to concatenate trials if the input is dictionary\n"," # expected input is of shape like output of getHistTrials\n","  \n","  keys = np.array(list(spikes_hist.keys()))\n","  no_trials, _ = np.shape(keys)\n","  out = spikes_hist[0,pick] # first trial\n","  if correct:\n","    target_val = 1\n","  else:\n","    target_val = -1\n","\n","  for trials in np.arange(1, int(no_trials/4)):\n","    if feedback[trials]==target_val:\n","      out = np.concatenate([out, spikes_hist[trials,pick]], axis = 1) # concatenating \n","\n","  return out\n","\n","def ReactStrength(Qref,Qtar, method = 'PCA'):\n","  \"\"\"\n","  inputs:       Qref binned spike train during the reference epoch (neurons x time)\n","                Qtar binned spike train during the target    epoch (neurons x time)\n","\n","  \"\"\"\n","  nCells = np.shape(Qref)[0]\n","  if nCells != np.shape(Qtar)[0]:\n","    error('''Qred'' and ''Qtar'' should have the same number of rows''') \n","\n","  Cref = np.corrcoef(Qref) # neuron x neuron\n","  lambdas, PCs  = np.linalg.eigh(Cref)\n","  lambdas = np.flip(lambdas)\n","  PCs     = np.flip(PCs, axis=1)\n","  #Marcenko-Pastur threshold\n","  lMax = (1 + np.sqrt(nCells / np.shape(Qref)[1]))**2\n","\n","  nPCs     = np.sum(lambdas>lMax)\n","  phi      = lambdas[0:nPCs]/lMax\n","\n","  if method == 'ICA':\n","    ica    = FastICA(n_components=nPCs, random_state=0) \n","    PCs    = ica.fit_transform(scipy.stats.zscore(Qref))\n","\n","  scoreTar = scipy.stats.zscore(Qtar,axis=1).T @ PCs[:,0:nPCs]\n","  tmp      = [scipy.stats.zscore(Qtar,axis=1).T**2] @ PCs[:,0:nPCs]**2\n","  R        = scoreTar**2 - tmp\n","  R = np.squeeze(R) # time x number of sig. PCs \n","  return R, PCs, lambdas\n","\n","\n","def create_brain_area_list():\n","  # groupings of brain regions\n","  brain_regions = [\"vis ctx\", \"thal\", \"hipp\", \"other ctx\", \"midbrain\", \"basal ganglia\", \"cortical subplate\", \"other\"]\n","  brain_areas = [[\"VISa\", \"VISam\", \"VISl\", \"VISp\", \"VISpm\", \"VISrl\"], # visual cortex\n","                [\"CL\", \"LD\", \"LGd\", \"LH\", \"LP\", \"MD\", \"MG\", \"PO\", \"POL\", \"PT\", \"RT\", \"SPF\", \"TH\", \"VAL\", \"VPL\", \"VPM\"], # thalamus\n","                [\"CA\", \"CA1\", \"CA2\", \"CA3\", \"DG\", \"SUB\", \"POST\"], # hippocampal\n","                [\"ACA\", \"AUD\", \"COA\", \"DP\", \"ILA\", \"MOp\", \"MOs\", \"OLF\", \"ORB\", \"ORBm\", \"PIR\", \"PL\", \"SSp\", \"SSs\", \"RSP\",\" TT\"], # non-visual cortex\n","                [\"APN\", \"IC\", \"MB\", \"MRN\", \"NB\", \"PAG\", \"RN\", \"SCs\", \"SCm\", \"SCig\", \"SCsg\", \"ZI\"], # midbrain\n","                [\"ACB\", \"CP\", \"GPe\", \"LS\", \"LSc\", \"LSr\", \"MS\", \"OT\", \"SNr\", \"SI\"], # basal ganglia \n","                [\"BLA\", \"BMA\", \"EP\", \"EPd\", \"MEA\"] # cortical subplate\n","                ]\n","\n","  return brain_regions, brain_areas\n","\n","def get_cells2keep(drivepath):\n","  '''\n","  Finds only the good and useable clusters. Loads _phy_annotation to do so.\n","\n","  input:  drivepath (file location)\n","  output: cells2keep: boolean array (size: [ncluster,]): 1 keep, 0 toss\n","  '''\n","  phyLabel = np.load(drivepath + 'clusters._phy_annotation.npy') # 0: excluded/noise    1: excluded because MUA   2: good    3: unsorted\n","  \n","  cells2keep = phyLabel >= 2 # take only cells with good labels \n","  cells2keep = np.squeeze(cells2keep) # boolean array: 1 keep, 0 toss\n","  return cells2keep\n","\n","  \n","def get_brain_area(cells2keep,drivepath):\n","  '''\n","  Finds brain areas for the good and useable clusters.\n","  Loads the brainLocation.tsv for every channel and finding the most likely  \n","  channel for every cluster. \n","\n","  input:  cells2keep (from function get_cells2keep)\n","            boolean array. size: [ncluster,]): 1 keep, 0 toss\n","          drivepath (file location)\n","  output: loc2keep Brain location acronym (Allen Brain based). \n","            ndarray of size: [ngoodCluster,]\n","          brain_area_indx. same size as loc2keep. us to index \n","            brain_regions (from get_brain_area_list)\n","  '''\n","  # load needed files\n","  chanLocs = pd.read_csv(drivepath + \"channels.brainLocation.tsv\",sep='\\t') # get channel locations \n","  peakChan = np.load(drivepath + 'clusters.peakChannel.npy') # find corresponding channel for each cluster\n","\n","  # process / index\n","  chanLocs = chanLocs['allen_ontology']\n","  peakChan = np.squeeze(peakChan)\n","  cellLoc = chanLocs[peakChan]\n","  cellLoc = cellLoc.to_numpy()\n","  loc2keep = cellLoc[cells2keep]\n","\n","  ###\n","  brain_regions, brain_areas = create_brain_area_list()\n","  brain_area_indx = np.zeros(loc2keep.shape)\n","\n","  for id in range(len(brain_area_indx)):\n","    area_idx = np.zeros((len(brain_areas)))\n","    for area in range(len(brain_areas)):\n","      area_idx[area] = np.isin(loc2keep[id], brain_areas[area])\n","    brain_area_indx[id] = area_idx.argmax()\n","\n","  return loc2keep, brain_area_indx\n","\n","def getHistTrials(spike_matrix_binned_sparse, binSize, trial_times, trials_idx, stim_time, brain_area_indx, brain_area_of_interest_indx):\n","  \"\"\" a function that transforms a sparse matrix into separate histograms for resting and task performance periods\n","  args:           spike_matrix_binned_sparse - sparse logical matrix with all cells\n","                  binSize                         - time bin size = bins per second (1000 corresponds to ms)\n","                  trial_times                     - 2D numpy array with trial start, trial stop\n","                  trials_idx                      - indices of trials of interest\n","                  stim_time                       - stimulation time, has to be same length as trial_times\n","                  brain_area_indx                 - an integer array with brain location idx of each unit\n","                  brain_area_of_interest_indx     - integer array with areas of interest\n","\n","  output:         trialsHist                 - n_trial X 4 dictionary with keys: 1) histogram of rest period\n","                                                                                 2) time stamps of rest period\n","                                                                                 3) histogram of task period\n","                                                                                 3) time stamps of task period\n","  \"\"\"\n","  trialsHist  = {} # set up the dictionary\n","  fullMat     = spike_matrix_binned_sparse.toarray()\n","  time        = np.linspace(0, np.shape(fullMat)[1]*binSize, np.shape(fullMat)[1])\n","  trials2keep = trial_times[trials_idx,:]\n","  stim2keep   = stim_time[trials_idx]\n","  cells2keep = brain_area_indx == brain_area_of_interest_indx\n","  # cells2keep  = np.isin(brain_area_indx, brain_area_of_interest) \n","  # brain_area_indx==brain_area_of_interest # gives only 1 boolean value, and we need to index all neurons (and keep ones that are in that brain region)   \n","  #np.isin(brain_loc, areas) # old notation\n","  \n","  print('# cells that are in brain area:', np.sum(cells2keep))\n","  \n","  if(np.sum(cells2keep) == 0):\n","    # raise exception('this brain area was not recorded, ask for another pls')\n","    print('this brain area was not recorded and is skipped')\n","  else:  \n","    for triali in range(np.shape(trials2keep)[0]):  \n","      start   = np.argmin(np.abs(time - trials2keep[triali,0]))\n","      stop    = np.argmin(np.abs(time - trials2keep[triali,1]))\n","      stim    = np.argmin(np.abs(time - stim2keep[triali]))\n","      parMatRest  = fullMat[cells2keep,start:stim]\n","      parMatTask  = fullMat[cells2keep,stim:stop]\n","      timevecRest = np.linspace(trials2keep[triali,0],stim2keep[triali], np.shape(parMatRest)[1] )\n","      timevecTask = np.linspace(stim2keep[triali], trials2keep[triali,1], np.shape(parMatTask)[1] )\n","\n","      #save into a dictionary\n","      trialsHist[triali,0] = parMatRest\n","      trialsHist[triali,1] = parMatTask\n","      trialsHist[triali,2] = timevecRest\n","      trialsHist[triali,3] = timevecTask \n","\n","    # print(triali)\n","    return trialsHist"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ar2e8kll1vdv","colab_type":"code","colab":{}},"source":["# get session data\n","drivepath = 'drive/My Drive/NMA/Lederberg_2017-12-05/' \n","\n","def getData(drivepath):\n","\n","  cells2keep  = get_cells2keep(drivepath)\n","  brain_areas, brain_areas_idx = get_brain_area(cells2keep,drivepath)\n","  trials_times, stim_time, _ ,_ , _ = load_all_timestamps_of_trials(drivepath)\n","  feedback = np.load(drivepath+'trials.feedbackType.npy')\n","  areas_list, _ = create_brain_area_list() \n","\n","  if not path.isfile(drivepath+'spikes_binned_ms_sparse.npz'): # hasn't been created yet\n","    print('grabbing spike times...')\n","    spike_matrix = create_spike_matrix(cells2keep) # spike times for each good cluster\n","    print('binning spike times...')\n","    spike_matrix_binned = create_time_binned_spike_matrix(spike_matrix) # boolean array in ms for each cluster = row\n","    print('sparsifying and saving spike_matrix_binned...')\n","    # save_sparse(spike_matrix_binned,drivepath)    # sparsify for storage/memory reason\n","    spike_matrix_binned_sparse = save_sparse(spike_matrix_binned,drivepath) # sparsify for storage/memory reason\n","  else:\n","    print('found pre-computed sparse spiking matrix. loading...')\n","    spike_matrix_binned_sparse = scipy.sparse.load_npz(drivepath+'spikes_binned_ms_sparse.npz')\n","    # if need dense matrix\n","    # spike_matrix_binned = scipy.sparse.ourBelovedSparseMatrix.todense(spike_matrix_binned_sparse)\n","\n","  return spike_matrix_binned_sparse, trials_times, stim_time, brain_areas, brain_areas_idx, feedback,areas_list\n","\n","def get_rid_of_silent_neurons(Qref, Qtar):\n","  r = np.any(Qref, axis=1)\n","  t = np.any(Qtar, axis=1) \n","  r = r[:, np.newaxis]\n","  t = t[:, np.newaxis]\n","  all = np.append(r,t,axis=1)\n","  s = np.sum(all,axis=1)\n","  kp = s == 2\n","\n","  Qref = Qref[kp,:]\n","  Qtar = Qtar[kp,:]\n","  return Qref, Qtar"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ypj_f6oaLm28","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"8njwCyZ3CJTH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596031743534,"user_tz":-120,"elapsed":1505601,"user":{"displayName":"nnitzan@live.com","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi15LnFMHvurnlHrFrn0hYm0WrcfjCDaBBtj1Ew=s64","userId":"06961482040564309913"}},"outputId":"7f34a559-aa38-47d8-caa6-c84585746a7f"},"source":["# initialize output dict \n","\n","dates = ['05', '06', '07', '08', '09', '10']\n","st = 'drive/My Drive/NMA/Lederberg_2017-12-' \n","\n","R_all_corr = { (st+dates[0]): {} ,(st+dates[1]): {} ,(st+dates[2]): {} ,(st+dates[3]): {} ,(st+dates[4]): {} ,(st+dates[5]): {} }\n","R_all_incorr = { (st+dates[0]): {} ,(st+dates[1]): {} ,(st+dates[2]): {} ,(st+dates[3]): {} ,(st+dates[4]): {} ,(st+dates[5]): {}  } \n","PCs_all_corr = { (st+dates[0]): {} ,(st+dates[1]): {} ,(st+dates[2]): {} ,(st+dates[3]): {} ,(st+dates[4]): {} ,(st+dates[5]): {}  }\n","PCs_all_incorr = { (st+dates[0]): {} ,(st+dates[1]): {} ,(st+dates[2]): {} ,(st+dates[3]): {} ,(st+dates[4]): {} ,(st+dates[5]): {}  }\n","lambdas_all_corr = { (st+dates[0]): {} ,(st+dates[1]): {} ,(st+dates[2]): {} ,(st+dates[3]): {} ,(st+dates[4]): {} ,(st+dates[5]): {}  }\n","lambdas_all_incorr = { (st+dates[0]): {} ,(st+dates[1]): {} ,(st+dates[2]): {} ,(st+dates[3]): {} ,(st+dates[4]): {} ,(st+dates[5]): {} }\n","\n","for sesi in range(len(dates)):\n","\n","  if sesi > 0 :\n","    del spike_matrix_binned_sparse\n","\n","  print('working on session ' + str(sesi))\n","\n","  drivepath = ('drive/My Drive/NMA/Lederberg_2017-12-' + dates[sesi] + '/' )\n","\n","  spike_matrix_binned_sparse, trials_times, stim_time, brain_areas, brain_areas_idx, feedback,areas_list = getData(drivepath)\n","\n","  for areai in range(len(areas_list)-1): \n","\n","    print('working on area ' + str(areai))\n","\n","    hist  = getHistTrials(spike_matrix_binned_sparse, 0.001, trials_times, np.arange(0, np.shape(trials_times)[0])  , stim_time, brain_areas_idx, areai)\n","\n","    if bool(hist):\n","      hist_correct_rest   = concatenate_trials_by_feedbackoutput(hist, 0, feedback, correct=True)\n","      hist_correct_task   = concatenate_trials_by_feedbackoutput(hist, 1, feedback, correct=True)\n","\n","      Qref_corr, Qtar_corr = get_rid_of_silent_neurons(hist_correct_task, hist_correct_rest)\n","\n","      del hist_correct_rest, hist_correct_task\n","\n","      Qref_corr = smoothHist(Qref_corr, 0.001, 0.03)\n","      Qtar_corr = smoothHist(Qtar_corr, 0.001, 0.03)\n","\n","      hist_incorrect_rest = concatenate_trials_by_feedbackoutput(hist, 0, feedback, correct=False)\n","      hist_incorrect_task = concatenate_trials_by_feedbackoutput(hist, 1, feedback, correct=False)\n","\n","      del hist\n","\n","      Qref_incorr, Qtar_incorr = get_rid_of_silent_neurons(hist_incorrect_task, hist_incorrect_rest)\n","\n","      del hist_incorrect_rest, hist_incorrect_task\n","\n","      Qref_incorr = smoothHist(Qref_incorr, 0.001, 0.03)\n","      Qtar_incorr = smoothHist(Qtar_incorr, 0.001, 0.03)\n","\n","      R_corr,   PCs_corr,   lambdas_corr   = ReactStrength(Qref_corr    ,Qtar_corr    , method = 'PCA')\n","      R_incorr, PCs_incorr, lambdas_incorr = ReactStrength(Qref_incorr  ,Qtar_incorr  , method = 'PCA')\n","\n","      del Qref_corr, Qref_incorr, Qtar_incorr, Qtar_corr\n","\n","      R_all_corr[drivepath[0:-1]][areai,0] = R_corr\n","      R_all_corr[drivepath[0:-1]][areai,1] = areas_list[areai]\n","\n","      R_all_incorr[drivepath[0:-1]][areai,0] = R_incorr\n","      R_all_incorr[drivepath[0:-1]][areai,1] = areas_list[areai]\n","\n","      PCs_all_corr[drivepath[0:-1]][areai,0] = PCs_corr\n","      PCs_all_corr[drivepath[0:-1]][areai,1] = areas_list[areai]\n","\n","      PCs_all_incorr[drivepath[0:-1]][areai,0] = PCs_incorr\n","      PCs_all_incorr[drivepath[0:-1]][areai,1] = areas_list[areai]\n","\n","      lambdas_all_corr[drivepath[0:-1]][areai,0] = lambdas_corr\n","      lambdas_all_corr[drivepath[0:-1]][areai,1] = areas_list[areai]\n","\n","      lambdas_all_incorr[drivepath[0:-1]][areai,0] = lambdas_incorr\n","      lambdas_all_incorr[drivepath[0:-1]][areai,1] = areas_list[areai]\n","\n","      del R_corr, PCs_corr, lambdas_corr, R_incorr, PCs_incorr, lambdas_incorr\n","\n","BASE_PATH = \"drive/My Drive/NMA/\"\n","file_name = \"all_ses.npz\"\n","np.savez( os.path.join(BASE_PATH, file_name), R_all_corr, R_all_incorr,PCs_all_corr, PCs_all_incorr ,lambdas_all_corr,lambdas_all_incorr )"],"execution_count":null,"outputs":[{"output_type":"stream","text":["working on session 0\n","found pre-computed sparse spiking matrix. loading...\n","working on area 0\n","# cells that are in brain area: 245\n","working on area 1\n","# cells that are in brain area: 155\n","working on area 2\n","# cells that are in brain area: 220\n","working on area 3\n","# cells that are in brain area: 78\n","working on area 4\n","# cells that are in brain area: 0\n","this brain area was not recorded and is skipped\n","working on area 5\n","# cells that are in brain area: 0\n","this brain area was not recorded and is skipped\n","working on area 6\n","# cells that are in brain area: 0\n","this brain area was not recorded and is skipped\n","working on session 1\n","found pre-computed sparse spiking matrix. loading...\n","working on area 0\n","# cells that are in brain area: 209\n","working on area 1\n","# cells that are in brain area: 150\n","working on area 2\n","# cells that are in brain area: 51\n","working on area 3\n","# cells that are in brain area: 288\n","working on area 4\n","# cells that are in brain area: 264\n","working on area 5\n","# cells that are in brain area: 21\n","working on area 6\n","# cells that are in brain area: 0\n","this brain area was not recorded and is skipped\n","working on session 2\n","found pre-computed sparse spiking matrix. loading...\n","working on area 0\n","# cells that are in brain area: 45\n","working on area 1\n","# cells that are in brain area: 0\n","this brain area was not recorded and is skipped\n","working on area 2\n","# cells that are in brain area: 99\n","working on area 3\n","# cells that are in brain area: 441\n","working on area 4\n","# cells that are in brain area: 171\n","working on area 5\n","# cells that are in brain area: 0\n","this brain area was not recorded and is skipped\n","working on area 6\n","# cells that are in brain area: 0\n","this brain area was not recorded and is skipped\n","working on session 3\n","found pre-computed sparse spiking matrix. loading...\n","working on area 0\n","# cells that are in brain area: 85\n","working on area 1\n","# cells that are in brain area: 282\n","working on area 2\n","# cells that are in brain area: 5\n","working on area 3\n","# cells that are in brain area: 0\n","this brain area was not recorded and is skipped\n","working on area 4\n","# cells that are in brain area: 100\n","working on area 5\n","# cells that are in brain area: 142\n","working on area 6\n","# cells that are in brain area: 129\n","working on session 4\n","found pre-computed sparse spiking matrix. loading...\n","working on area 0\n","# cells that are in brain area: 0\n","this brain area was not recorded and is skipped\n","working on area 1\n","# cells that are in brain area: 242\n","working on area 2\n","# cells that are in brain area: 23\n","working on area 3\n","# cells that are in brain area: 144\n","working on area 4\n","# cells that are in brain area: 65\n","working on area 5\n","# cells that are in brain area: 0\n","this brain area was not recorded and is skipped\n","working on area 6\n","# cells that are in brain area: 0\n","this brain area was not recorded and is skipped\n","working on session 5\n","found pre-computed sparse spiking matrix. loading...\n","working on area 0\n","# cells that are in brain area: 356\n","working on area 1\n","# cells that are in brain area: 166\n","working on area 2\n","# cells that are in brain area: 0\n","this brain area was not recorded and is skipped\n","working on area 3\n","# cells that are in brain area: 0\n","this brain area was not recorded and is skipped\n","working on area 4\n","# cells that are in brain area: 0\n","this brain area was not recorded and is skipped\n","working on area 5\n","# cells that are in brain area: 0\n","this brain area was not recorded and is skipped\n","working on area 6\n","# cells that are in brain area: 43\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"u3WpOOYoS6dU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"38d38ff7-8c99-42c6-eec8-f12361b68821"},"source":["# shuffle version\n","\n","%reset\n","\n","dates = ['05', '06', '07', '08', '09', '10', '11']\n","st = 'drive/My Drive/NMA/Lederberg_2017-12-' \n","\n","R_all_corr_sh = { (st+dates[0]): {} ,(st+dates[1]): {} ,(st+dates[2]): {} ,(st+dates[3]): {} ,(st+dates[4]): {} ,(st+dates[5]): {} ,(st+dates[6]): {}  }\n","R_all_incorr_sh = { (st+dates[0]): {} ,(st+dates[1]): {} ,(st+dates[2]): {} ,(st+dates[3]): {} ,(st+dates[4]): {} ,(st+dates[5]): {} ,(st+dates[6]): {}  } \n","#PCs_all_corr = { (st+dates[0]): {} ,(st+dates[1]): {} ,(st+dates[2]): {} ,(st+dates[3]): {} ,(st+dates[4]): {} ,(st+dates[5]): {} ,(st+dates[6]): {}  }\n","#PCs_all_incorr = { (st+dates[0]): {} ,(st+dates[1]): {} ,(st+dates[2]): {} ,(st+dates[3]): {} ,(st+dates[4]): {} ,(st+dates[5]): {} ,(st+dates[6]): {}  }\n","lambdas_all_corr_sh = { (st+dates[0]): {} ,(st+dates[1]): {} ,(st+dates[2]): {} ,(st+dates[3]): {} ,(st+dates[4]): {} ,(st+dates[5]): {} ,(st+dates[6]): {}  }\n","lambdas_all_incorr_sh = { (st+dates[0]): {} ,(st+dates[1]): {} ,(st+dates[2]): {} ,(st+dates[3]): {} ,(st+dates[4]): {} ,(st+dates[5]): {} ,(st+dates[6]): {}  }\n","\n","nperm = 100\n","\n","for sesi in range(len(dates)):\n","\n","  if sesi > 0 :\n","\n","    del spike_matrix_binned_sparse\n","\n","  print('working on session ' + str(sesi))\n","\n","  drivepath = ('drive/My Drive/NMA/Lederberg_2017-12-' + dates[sesi] + '/' )\n","\n","  spike_matrix_binned_sparse, trials_times, stim_time, brain_areas, brain_areas_idx, feedback,areas_list = getData(drivepath)\n","\n","  brain_areas_idx_sh = np.random.permutation (brain_areas_idx)\n","\n","  for permi in range(nperm):\n","\n","    for areai in range(len(areas_list)-1): \n","\n","      print('working on area ' + str(areai))\n","\n","      hist  = getHistTrials(spike_matrix_binned_sparse, 0.001, trials_times, np.arange(0, np.shape(trials_times)[0])  , stim_time, brain_areas_idx_sh, areai)\n","\n","      if bool(hist):\n","        hist_correct_rest   = concatenate_trials_by_feedbackoutput(hist, 0, feedback, correct=True)\n","        hist_correct_task   = concatenate_trials_by_feedbackoutput(hist, 1, feedback, correct=True)\n","\n","        Qref_corr, Qtar_corr = get_rid_of_silent_neurons(hist_correct_task, hist_correct_rest)\n","\n","        Qref_corr = smoothHist(Qref_corr, 0.001, 0.03)\n","        Qtar_corr = smoothHist(Qtar_corr, 0.001, 0.03)\n","\n","        del hist_correct_rest, hist_correct_task\n","\n","        print('concatenating files...')\n","        hist_incorrect_rest = concatenate_trials_by_feedbackoutput(hist, 0, feedback, correct=False)\n","        hist_incorrect_task = concatenate_trials_by_feedbackoutput(hist, 1, feedback, correct=False)\n","\n","        del hist\n","\n","        Qref_incorr, Qtar_incorr = get_rid_of_silent_neurons(hist_incorrect_task, hist_incorrect_rest)\n","\n","        del hist_incorrect_rest, hist_incorrect_task\n","\n","        Qref_incorr = smoothHist(Qref_incorr, 0.001, 0.03)\n","        Qtar_incorr = smoothHist(Qtar_incorr, 0.001, 0.03)\n","        print('calculating reactivations...')\n","        R_corr,   PCs_corr,   lambdas_corr   = ReactStrength(Qref_corr    ,Qtar_corr    , method = 'PCA')\n","        R_incorr, PCs_incorr, lambdas_incorr = ReactStrength(Qref_incorr  ,Qtar_incorr  , method = 'PCA')\n","\n","        del Qref_corr, Qref_incorr, Qtar_incorr, Qtar_corr\n","\n","        R_all_corr_sh[drivepath[0:-1]][areai,0,permi] = R_corr[:,0]\n","        #R_all_corr[drivepath[0:-1]][areai,1,permi] = areas_list[areai]\n","\n","        R_all_incorr_sh[drivepath[0:-1]][areai,0,permi] = R_incorr[:,0]\n","        #R_all_incorr[drivepath[0:-1]][areai,1,permi] = areas_list[areai]\n","\n","        #PCs_all_corr[drivepath[0:-1]][areai,0] = PCs_corr\n","        #PCs_all_corr[drivepath[0:-1]][areai,1] = areas_list[areai]\n","\n","        #PCs_all_incorr[drivepath[0:-1]][areai,0] = PCs_incorr\n","        #PCs_all_incorr[drivepath[0:-1]][areai,1] = areas_list[areai]\n","\n","        lambdas_all_corr_sh[drivepath[0:-1]][areai,0,permi] = lambdas_corr\n","        #lambdas_all_corr_sh[drivepath[0:-1]][areai,1,permi] = areas_list[areai]\n","\n","        lambdas_all_incorr_sh[drivepath[0:-1]][areai,0,permi] = lambdas_incorr\n","        #lambdas_all_incorr_sh[drivepath[0:-1]][areai,1,permi] = areas_list[areai]\n","\n","        del R_corr, PCs_corr, lambdas_corr, R_incorr, PCs_incorr, lambdas_incorr\n","\n","        BASE_PATH = \"drive/My Drive/NMA/\"\n","        file_name = \"all_ses_sh.npz\"\n","        np.savez( os.path.join(BASE_PATH, file_name), R_all_corr_sh, R_all_incorr_sh,lambdas_all_corr_sh,lambdas_all_incorr_sh)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Once deleted, variables cannot be recovered. Proceed (y/[n])? n\n","Nothing done.\n","working on session 0\n","found pre-computed sparse spiking matrix. loading...\n","working on area 0\n","# cells that are in brain area: 245\n","concatenating files...\n","calculating reactivations...\n","working on area 1\n","# cells that are in brain area: 155\n","concatenating files...\n","calculating reactivations...\n","working on area 2\n","# cells that are in brain area: 220\n","concatenating files...\n","calculating reactivations...\n","working on area 3\n","# cells that are in brain area: 78\n","concatenating files...\n","calculating reactivations...\n","working on area 4\n","# cells that are in brain area: 0\n","this brain area was not recorded and is skipped\n","working on area 5\n","# cells that are in brain area: 0\n","this brain area was not recorded and is skipped\n","working on area 6\n","# cells that are in brain area: 0\n","this brain area was not recorded and is skipped\n","working on area 0\n","# cells that are in brain area: 245\n","concatenating files...\n","calculating reactivations...\n","working on area 1\n","# cells that are in brain area: 155\n","concatenating files...\n","calculating reactivations...\n","working on area 2\n","# cells that are in brain area: 220\n","concatenating files...\n","calculating reactivations...\n","working on area 3\n","# cells that are in brain area: 78\n","concatenating files...\n","calculating reactivations...\n","working on area 4\n","# cells that are in brain area: 0\n","this brain area was not recorded and is skipped\n","working on area 5\n","# cells that are in brain area: 0\n","this brain area was not recorded and is skipped\n","working on area 6\n","# cells that are in brain area: 0\n","this brain area was not recorded and is skipped\n","working on area 0\n","# cells that are in brain area: 245\n","concatenating files...\n","calculating reactivations...\n","working on area 1\n","# cells that are in brain area: 155\n","concatenating files...\n","calculating reactivations...\n","working on area 2\n","# cells that are in brain area: 220\n","concatenating files...\n","calculating reactivations...\n","working on area 3\n","# cells that are in brain area: 78\n","concatenating files...\n","calculating reactivations...\n","working on area 4\n","# cells that are in brain area: 0\n","this brain area was not recorded and is skipped\n","working on area 5\n","# cells that are in brain area: 0\n","this brain area was not recorded and is skipped\n","working on area 6\n","# cells that are in brain area: 0\n","this brain area was not recorded and is skipped\n","working on area 0\n","# cells that are in brain area: 245\n","concatenating files...\n","calculating reactivations...\n","working on area 1\n","# cells that are in brain area: 155\n","concatenating files...\n","calculating reactivations...\n","working on area 2\n","# cells that are in brain area: 220\n","concatenating files...\n","calculating reactivations...\n","working on area 3\n","# cells that are in brain area: 78\n","concatenating files...\n","calculating reactivations...\n","working on area 4\n","# cells that are in brain area: 0\n","this brain area was not recorded and is skipped\n","working on area 5\n","# cells that are in brain area: 0\n","this brain area was not recorded and is skipped\n","working on area 6\n","# cells that are in brain area: 0\n","this brain area was not recorded and is skipped\n","working on area 0\n","# cells that are in brain area: 245\n","concatenating files...\n","calculating reactivations...\n","working on area 1\n","# cells that are in brain area: 155\n","concatenating files...\n","calculating reactivations...\n","working on area 2\n","# cells that are in brain area: 220\n","concatenating files...\n","calculating reactivations...\n","working on area 3\n","# cells that are in brain area: 78\n","concatenating files...\n","calculating reactivations...\n","working on area 4\n","# cells that are in brain area: 0\n","this brain area was not recorded and is skipped\n","working on area 5\n","# cells that are in brain area: 0\n","this brain area was not recorded and is skipped\n","working on area 6\n","# cells that are in brain area: 0\n","this brain area was not recorded and is skipped\n","working on area 0\n","# cells that are in brain area: 245\n","concatenating files...\n","calculating reactivations...\n","working on area 1\n","# cells that are in brain area: 155\n","concatenating files...\n","calculating reactivations...\n","working on area 2\n","# cells that are in brain area: 220\n","concatenating files...\n","calculating reactivations...\n","working on area 3\n","# cells that are in brain area: 78\n","concatenating files...\n","calculating reactivations...\n","working on area 4\n","# cells that are in brain area: 0\n","this brain area was not recorded and is skipped\n","working on area 5\n","# cells that are in brain area: 0\n","this brain area was not recorded and is skipped\n","working on area 6\n","# cells that are in brain area: 0\n","this brain area was not recorded and is skipped\n","working on area 0\n","# cells that are in brain area: 245\n","concatenating files...\n","calculating reactivations...\n","working on area 1\n","# cells that are in brain area: 155\n","concatenating files...\n","calculating reactivations...\n","working on area 2\n","# cells that are in brain area: 220\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Xl6GIchmE7bg","colab_type":"code","colab":{}},"source":["  drivepath = ('drive/My Drive/NMA/Lederberg_2017-12-' + '05' + '/' )"],"execution_count":null,"outputs":[]}]}